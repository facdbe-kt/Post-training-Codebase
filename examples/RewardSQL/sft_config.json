{
  "model_id_or_path": "Qwen/Qwen2.5-Coder-7B-Instruct",
  "output_dir": "/fs/fast/u2020201469/models/saves/Qwen2.5-Coder-7B-Instruct/mschema_reject_sampling",
  "dataset": ["/home/u2020201469/NL2SQL/CTE_reasoner/SLM_module/reject_sampling/processed_results/18k_merge/rs_18k_for_sft_reward_rank_exFilter_min0_5.json"],
  "max_length": 8192,
  "learning_rate": 1e-5,
  "per_device_train_batch_size": 2,
  "gradient_checkpointing": true,
  "gradient_accumulation_steps": 16,
  "save_strategy": "epoch",
  "eval_steps": 500,
  "save_total_limit": 20,
  "torch_dtype": "bfloat16",
  "deepspeed_config": "/home/u2020201469/NL2SQL/swift/swift/llm/ds_config/zero3.json",
  "lora_rank": 8,
  "lora_alpha": 32,
  "train_type": "full",
  "use_liger": true,
  "model_type": "qwen2_5",
  "template": "qwen2_5",
  "init_weights": true,
  "attn_impl": "flash_attn",
  "ignore_args_error": true,
  "save_only_model": true,
  "use_chat_template": false
} 